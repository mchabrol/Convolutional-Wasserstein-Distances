{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.image_treatment import preprocess_image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from wasserstein.basic_wasserstein import compute_sliced_wass_barycenter\n",
    "import pyrtools as pt\n",
    "from tqdm import tqdm \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path1 = 'data/elephant.jpg'\n",
    "image_path2 = 'data/gateau.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = preprocess_image(image_path1, new_size = (200,200))\n",
    "image2 = preprocess_image(image_path2, new_size = (200,200))\n",
    "textures = [image1, image2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_steerable_pyramid_coeffs(image, num_scales=4, num_orientations=4):\n",
    "    \"\"\"\n",
    "    Compute steerable pyramid coefficients with specified orientations using pyrtools.\n",
    "    \n",
    "    Parameters:\n",
    "    - image: 2D numpy array, input grayscale image.\n",
    "    - num_scales: int, number of scales.\n",
    "    - num_orientations: int, number of orientations.\n",
    "\n",
    "    Returns:\n",
    "    - coeffs: Dictionary of coefficients organized by scale and orientation.\n",
    "    \"\"\"\n",
    "    # Initialize the steerable pyramid\n",
    "    pyramid = pt.pyramids.SteerablePyramidFreq(image, height=num_scales, order=num_orientations-1)\n",
    "\n",
    "    return pyramid.pyr_coeffs, pyramid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef, pyr = compute_steerable_pyramid_coeffs(image1[:,:,1], num_scales=4, num_orientations=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 200)\n",
      "(200, 200)\n",
      "(200, 200)\n",
      "(200, 200)\n",
      "(200, 200)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(50, 50)\n",
      "(50, 50)\n",
      "(50, 50)\n",
      "(50, 50)\n",
      "(25, 25)\n",
      "(25, 25)\n",
      "(25, 25)\n",
      "(25, 25)\n",
      "(13, 13)\n"
     ]
    }
   ],
   "source": [
    "for key in coef.keys():\n",
    "    print(coef[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "All images must be able to be 'zoomed in' to the largest image.That is, the largest image must be a scalar multiple of all images.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[222], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyrshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoef\u001b[49m\u001b[43m)\u001b[49m;\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pyrtools/tools/display.py:942\u001b[0m, in \u001b[0;36mpyrshow\u001b[0;34m(pyr_coeffs, is_complex, vrange, col_wrap, zoom, show_residuals, **kwargs)\u001b[0m\n\u001b[1;32m    940\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fig\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvrange\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvrange\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol_wrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcol_wrap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzoom\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzoom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtitles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pyrtools/tools/display.py:703\u001b[0m, in \u001b[0;36mimshow\u001b[0;34m(image, vrange, zoom, title, col_wrap, ax, cmap, plot_complex, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m image, title, contains_rgb \u001b[38;5;241m=\u001b[39m _process_signal(image, title, plot_complex)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# make sure we can properly zoom all images\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m zooms, max_shape \u001b[38;5;241m=\u001b[39m \u001b[43m_check_zooms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzoom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontains_rgb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# get the figure and axes created\u001b[39;00m\n\u001b[1;32m    706\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m _setup_figure(ax, col_wrap, image, zoom, max_shape, vert_pct)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pyrtools/tools/display.py:570\u001b[0m, in \u001b[0;36m_check_zooms\u001b[0;34m(signal, zoom, contains_rgb, video)\u001b[0m\n\u001b[1;32m    567\u001b[0m         max_shape \u001b[38;5;241m=\u001b[39m signal[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;66;03m# then we have multiple images/videos that are different shapes\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     zooms, max_shape \u001b[38;5;241m=\u001b[39m \u001b[43mfind_zooms\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    571\u001b[0m max_shape \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(max_shape)\n\u001b[1;32m    572\u001b[0m zooms \u001b[38;5;241m=\u001b[39m zoom \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39marray(zooms)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pyrtools/tools/display.py:365\u001b[0m, in \u001b[0;36mfind_zooms\u001b[0;34m(images, video)\u001b[0m\n\u001b[1;32m    363\u001b[0m max_shape \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m--> 365\u001b[0m     max_shape\u001b[38;5;241m.\u001b[39mappend(\u001b[43mcheck_shape_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mtime_dim\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    366\u001b[0m zooms \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m images:\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# this checks that there's only one unique value in the list\u001b[39;00m\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;66;03m# max_shape[i] // img.shape[i], where i indexes through the dimensions;\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;66;03m# the first two non-time dimensions (so we'll ignore the RGBA channel\u001b[39;00m\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;66;03m# if any image has that)\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pyrtools/tools/display.py:354\u001b[0m, in \u001b[0;36mfind_zooms.<locals>.check_shape_1d\u001b[0;34m(shapes)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m shapes:\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (max_shape \u001b[38;5;241m%\u001b[39m s) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 354\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll images must be able to be \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzoomed in\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to the largest image.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    355\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThat is, the largest image must be a scalar multiple of all \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    356\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m max_shape\n",
      "\u001b[0;31mException\u001b[0m: All images must be able to be 'zoomed in' to the largest image.That is, the largest image must be a scalar multiple of all images."
     ]
    }
   ],
   "source": [
    "pt.pyrshow(coef);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_3D_wavelets_coeffs(image, num_scales=4, num_orientations=4):\n",
    "    \"\"\"\n",
    "    Compute wavelets coefficients (highpass, bandpass, low-residuals) for the 3 channels (R,G,B) of an image\n",
    "    \n",
    "    Parameters:\n",
    "    - image: 2D numpy array, input grayscale image.\n",
    "    - num_scales: int, number of scales.\n",
    "    - num_orientations: int, number of orientations.\n",
    "\n",
    "    Returns:\n",
    "    - wavelets_coeffs: Dictionary of coefficients organized by channel (R,G,B) and then by bandpass (highpass, bandpass -scale and orientation- and low residual).\n",
    "    \"\"\"\n",
    "    wavelets_coeffs = {}\n",
    "    rgb = ['R','G','B']\n",
    "    for channel in range(3):\n",
    "        wavelets_coeffs[rgb[channel]] = compute_steerable_pyramid_coeffs(image[:, :, channel], num_scales=num_scales, num_orientations=num_orientations)\n",
    "    return(wavelets_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_wavelet_coeffs_barycenter(textures, num_scales=4, num_orientations=4):\n",
    "    \"\"\"\n",
    "    Compute the barycenter of wavelets coefficients --> Y^l (see page 9 in paper)\n",
    "    \n",
    "    Parameters:\n",
    "    - textures: 3D numpy array, input RGB image.\n",
    "    - num_scales: int, number of scales.\n",
    "    - num_orientations: int, number of orientations.\n",
    "\n",
    "    Returns:\n",
    "    - bar_wavelet_coeffs_RGB: Dictionary of barycenters of wavelets coefficients by channel (R,G,B) and then by highpass/bandpass/lowresidual\n",
    "    \"\"\"\n",
    "\n",
    "    bar_wavelet_coeffs = {}\n",
    "    bar_wavelet_coeffs_RGB = {}\n",
    "    RGB = ['R','G','B']\n",
    "    wavelets_coeffs = [compute_3D_wavelets_coeffs(image) for image in textures]\n",
    "\n",
    "    for rgb in RGB:\n",
    "        for k in wavelets_coeffs[0][rgb].keys():\n",
    "                distributions = [w[rgb][k].reshape(-1,1) for w in wavelets_coeffs] #reshape --> flattens the image to compute the barycenter\n",
    "                n = int(np.sqrt(distributions[0].shape[0]))\n",
    "                bar_wavelet_coeffs[k] = (compute_sliced_wass_barycenter(distributions, rho = None)).reshape(n, n)\n",
    "        bar_wavelet_coeffs_RGB[rgb] = bar_wavelet_coeffs\n",
    "    return(bar_wavelet_coeffs_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_l = compute_wavelet_coeffs_barycenter(textures, num_scales=4, num_orientations=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Yl.pkl', 'rb') as file:\n",
    "        # Loading the data from the pickle file\n",
    "        Y_l = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_random_image(size=(256, 256), channels=3):\n",
    "    \"\"\"Initialize a random white noise image f^(0).\"\"\"\n",
    "    return np.random.rand(*size, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection(X0, Y):\n",
    "    \"\"\"\n",
    "    X0 : image a projeter \n",
    "    Y : ce sur quoi on veut projeter \n",
    "    \"\"\"\n",
    "    Y_distrib = [Y]\n",
    "    proj = compute_sliced_wass_barycenter(Y_distrib, rho = None, lr = 1e3, k = 200,  nb_iter_max = 50, xbinit = X0)\n",
    "    return(proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dict(d, parent_key='', sep='.'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_dict_to_RGB_array(dico):\n",
    "\n",
    "    output_dict = {}\n",
    "\n",
    "    # Extract unique filter types by parsing keys\n",
    "    filters = set(key.split('.')[1] for key in dico.keys())\n",
    "\n",
    "    # Iterate through each unique filter\n",
    "    for filter_type in filters:\n",
    "        # Collect the R, G, B arrays for the current filter\n",
    "        r_key = f'R.{filter_type}'\n",
    "        g_key = f'G.{filter_type}'\n",
    "        b_key = f'B.{filter_type}'\n",
    "        \n",
    "        if r_key in dico and g_key in dico and b_key in dico:\n",
    "            # Stack R, G, B arrays along a new third axis to form a (P, Q, 3) array\n",
    "            rgb_array = np.stack([dico[r_key], dico[g_key], dico[b_key]], axis=-1)\n",
    "            \n",
    "            # Add to output dictionary\n",
    "            output_dict[filter_type] = rgb_array\n",
    "    return(output_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_0 = initialize_random_image(size=(75, 75), channels=3)\n",
    "f_0_pyr = compute_3D_wavelets_coeffs(f_0, num_scales=4, num_orientations=4)\n",
    "f_0_pyr = flatten_dict(f_0_pyr)\n",
    "f_0_pyr = from_dict_to_RGB_array(f_0_pyr)\n",
    "#Y_l = from_dict_to_RGB_array(Y_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_l_n = {}\n",
    "for key in Y_l.keys():\n",
    "    Y_l_filter = Y_l[key].reshape(-1,3)\n",
    "    f_0_filter = f_0_pyr[key].reshape(-1,3)\n",
    "    c_l_n[key] = projection(f_0_filter, Y_l_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def from_str_to_tuple_dict(data_dict):\n",
    "\n",
    "    # New dictionary to hold the modified keys\n",
    "    modified_dict = {}\n",
    "\n",
    "    # Iterate over the original dictionary\n",
    "    for key, value in data_dict.items():\n",
    "        # Try to convert keys that look like tuples into actual tuple types\n",
    "        try:\n",
    "            # Use ast.literal_eval to safely evaluate keys that are tuples as strings\n",
    "            evaluated_key = ast.literal_eval(key)\n",
    "            if isinstance(evaluated_key, tuple):\n",
    "                modified_dict[evaluated_key] = value\n",
    "            else:\n",
    "                modified_dict[key] = value\n",
    "        except (ValueError, SyntaxError):\n",
    "            # If the key isn't a tuple-like string, keep it as-is\n",
    "            modified_dict[key] = value\n",
    "    return(modified_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_l_n = from_str_to_tuple_dict(c_l_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_r = {}\n",
    "dict_g = {}\n",
    "dict_b = {}\n",
    "\n",
    "for key in c_l_n.keys():\n",
    "    size = int(np.sqrt(c_l_n[key].shape[0]))\n",
    "    dict_r[key] = c_l_n[key][:,0].reshape(size, size)\n",
    "    dict_g[key] = c_l_n[key][:,1].reshape(size, size)\n",
    "    dict_b[key] = c_l_n[key][:,2].reshape(size, size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to a Pickle file\n",
    "# with open('c_l_n.pkl', 'wb') as file:\n",
    "#     pickle.dump(flatten_dict(c_l_n), file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
